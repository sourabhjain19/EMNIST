{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c722ff53d6ce9d3efd795d0b27622d6f2731cca8"
   },
   "source": [
    "Firstly, we need to load our data, notice that there is no column names in csv files and thus header shold be set to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
       "0   45    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1   36    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2   43    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3   15    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    4    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('emnist-balanced-train.csv', header=None)\n",
    "test = pd.read_csv('emnist-balanced-test.csv', header=None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1de1e3161fbb5508d50795ae5ec111fe9dece93"
   },
   "source": [
    "Now split labels and images from original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "873961cc8c68e670d8da4e1bc8f481b4285fd695"
   },
   "outputs": [],
   "source": [
    "train_data = train.iloc[:, 1:]\n",
    "train_labels = train.iloc[:, 0]\n",
    "test_data = test.iloc[:, 1:]\n",
    "test_labels = test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ce317f24e54de329fc8c70b29d5680327902eb3"
   },
   "source": [
    "One hot encoding with `get_dummies()` and you can compare it with the original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f579b8562191e84691329a20f9641ac67efbbb14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  37  38  39  40  41  42  43  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   \n",
       "3   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "4   0   0   0   0   1   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "   44  45  46  \n",
       "0   0   1   0  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.get_dummies(train_labels)\n",
    "test_labels = pd.get_dummies(test_labels)\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69cfc5f3f284179a4267d12099f7f75427191101"
   },
   "source": [
    "Turn our Dataframes into numpy array and delete `train` and `test` to save up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "99bd8b190cb539cb791c9679e71a63aab2740dd1"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.values\n",
    "train_labels = train_labels.values\n",
    "test_data = test_data.values\n",
    "test_labels = test_labels.values\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac3a3dcac965dec9dabb7e1ac7455e67055f8aca"
   },
   "source": [
    "For some reason, sadly, the EMNIST dataset was rotated and flipped and we need fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "378e0eba6eed6a4ffc1f684dcd205f0d7eecc7af"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(train_data[45].reshape([28, 28]), cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "202b20574a27ac0b98de387605a18af6e945080b"
   },
   "outputs": [],
   "source": [
    "def rotate(image):\n",
    "    image = image.reshape([28, 28])\n",
    "    image = np.fliplr(image)\n",
    "    image = np.rot90(image)\n",
    "    return image.reshape([28 * 28])\n",
    "train_data = np.apply_along_axis(rotate, 1, train_data)/255\n",
    "test_data = np.apply_along_axis(rotate, 1, test_data)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage, misc\n",
    "\n",
    "def rotate10(image):\n",
    "    img_45 = ndimage.rotate(image.reshape([28,28]), -15, reshape=False)\n",
    "#plt.imshow(img_45, cmap='Greys_r')\n",
    "    img_45=img_45.reshape(1,784)\n",
    "    img_45=img_45.ravel()\n",
    "    img_45.reshape(28,28)\n",
    "    return img_45\n",
    "train_data1 = np.apply_along_axis(rotate10, 1, train_data)\n",
    "test_data1 = np.apply_along_axis(rotate10, 1, test_data)\n",
    "#plt.imshow(img_45.reshape(28,28), cmap='Greys_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d=np.concatenate((train_data,train_data1))\n",
    "test_d=np.concatenate((test_data,test_data1))\n",
    "\n",
    "train_l=np.concatenate((train_labels,train_labels))\n",
    "test_l=np.concatenate((test_labels,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "808004dba9959f4571844c2292b0990b94074fe0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    path=\"sample\"+str(i)+\".png\"\n",
    "    fig=plt.imshow(train_data[i].reshape([28, 28]), cmap='Greys_r')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.savefig(path,bbox_inches='tight',pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "adf2ae2680fd52ba850af9554d66eb621f0e9bb1"
   },
   "source": [
    "Now let's import tensorflow to start building our network, with slim we can keep our code neat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "dc4e22b26f9c79d66c53d27c7a01ec8c1ceebe02"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "74dbac5263d3f949a01c7ed1ca732baaf78bf802"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "xs = tf.placeholder(tf.float32, [None, 784], name='input')\n",
    "ys = tf.placeholder(tf.float32, [None, 47], name='exp_output')\n",
    "dropout = tf.placeholder(tf.float32, name='dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "c2c45977878920e266dfb7e5c1b141480d230f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-14-5440ef950ae4>:3: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002A6ECCB9CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002A6ECCB9CC0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002A6ECCB9CC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002A6ECCB9CC0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-14-5440ef950ae4>:4: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000002A6ECC9A518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000002A6ECC9A518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000002A6ECC9A518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000002A6ECC9A518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-14-5440ef950ae4>:5: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000002A6E9EBB828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000002A6E9EBB828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000002A6E9EBB828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000002A6E9EBB828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002A6ECF93F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002A6ECF93F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002A6ECF93F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002A6ECF93F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000002A6E9EBB828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000002A6E9EBB828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000002A6E9EBB828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000002A6E9EBB828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-14-5440ef950ae4>:9: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECF93C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECF93C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECF93C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECF93C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-14-5440ef950ae4>:10: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECF9A4E0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECF9A4E0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECF9A4E0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECF9A4E0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000002A6ECD11470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000002A6ECD11470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000002A6ECD11470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000002A6ECD11470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECC9A518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECC9A518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECC9A518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECC9A518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECD11470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECD11470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECD11470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002A6ECD11470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    " # define the computation graph\n",
    "x_image = tf.reshape(xs, [-1, 28, 28, 1])\n",
    "layer = tf.layers.conv2d(x_image, 64, [5,5], padding='same', activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "layer = tf.layers.max_pooling2d(layer, pool_size=(2,2), strides=2) # [-1, 14, 14, 64]\n",
    "layer = tf.layers.batch_normalization(layer)\n",
    "layer = tf.layers.conv2d(layer, 128, [2,2], padding='same', activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "layer = tf.layers.max_pooling2d(layer, pool_size=(2,2), strides=2) # [-1, 7, 7, 128]\n",
    "x_flat = tf.reshape(layer, [-1, 7*7*128])\n",
    "flatten = tf.layers.dense(x_flat, 1024, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "flatten = tf.nn.dropout(flatten, keep_prob=1-dropout)\n",
    "flatten = tf.layers.dense(flatten, 512, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "flatten = tf.layers.batch_normalization(flatten)\n",
    "flatten = tf.layers.dense(flatten, 128, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "flatten = tf.layers.dense(flatten, 47)\n",
    "pred = tf.nn.softmax(flatten, name='output')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbd4bce186ab31cd63e970d3c9c7a22247ac9158"
   },
   "source": [
    "Now define our loss function, in this case, it is `softmax_cross_entropy_with_logits` but the official document shows it is deprecated as labels will be affected in backprop. But we use placeholders to feed data, and this is will not be a problem for us. In order to get rid of the warn info and keep our notebook neat, I use the `_v2` version. For more information on these two functions, you can refer to [StackExchange](https://stats.stackexchange.com/questions/327348/how-is-softmax-cross-entropy-with-logits-different-from-softmax-cross-entropy-wi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "b5905a309da68737c34fa739f0b64a3208b857d5"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    labels=ys,\n",
    "    logits=flatten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "d0c9f29e9491ea634f11f13efa296ee576165b35"
   },
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "correct = tf.equal(tf.argmax(flatten, 1), tf.argmax(ys, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "aff502a3d10b81ff0065a4e906d076157525d35c"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6292e1428355587fa910c0ced89fc4e0b7599ce"
   },
   "outputs": [],
   "source": [
    "NUM = 112800\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(20):\n",
    "        for i in range(int(NUM / 100)):\n",
    "            x_batches, y_batches = train_data[i * 100: (i + 1) * 100], train_labels[i * 100: (i + 1) * 100]\n",
    "            sess.run(train, feed_dict={xs: x_batches, ys: y_batches, dropout: 0.5})\n",
    "            \n",
    "            if i % 1000 == 0:\n",
    "                acc, entropy = sess.run([accuracy, cross_entropy], feed_dict={xs: test_data,\n",
    "                                                    ys: test_labels,\n",
    "                                                    dropout: 0})\n",
    "                print('Train Entropy : ', sess.run(cross_entropy, feed_dict={xs: x_batches, ys: y_batches, dropout: 0.5}))\n",
    "                print('Test Accr & Entropy : ', acc, entropy)\n",
    "                # save_and_generate_proto(sess)\n",
    "    acc = sess.run(accuracy, feed_dict={xs: test_data,\n",
    "                                                ys: test_labels,\n",
    "                                                dropout: 0})\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f744eff99b8e0c46c9f81bbc7601f032ce008098"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8fd281b37e9ea882924bd2b72bdce8dd5925ef8"
   },
   "source": [
    "The final accuracy of our network is about 88.27%.  We are using the same balanced dataset and achieved these results. We have normalized the input pixels by dividing them with 255, hence a boost in accuracy was achieved from 85 to 88%. We have also used batch norms to tackle with the problem of covarient shifts. From our training results we conclude that the model has high varience, it is evident from the fact that training loss got down to 0.15 and testing loss was 3 times more than training loss. With this we conclude either our model was overfitting or that train data is not enough. Since we have used dropouts, overfitting is not an issue, The issue is the dataset, We can gather more training data and that should possibly solve the problem of high varience."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
